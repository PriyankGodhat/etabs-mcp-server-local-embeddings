# .env.example

# --- ChromaDB Configuration ---
# Host and port for the ChromaDB server instance (used by Python indexer)
# Default assumes ChromaDB is running in Docker locally
CHROMA_HOST=http://localhost:8000
# Name for the ChromaDB collection where embeddings will be stored
CHROMA_COLLECTION_NAME=etabs_docs_local

# --- Embedding Model ---
# Name of the Sentence Transformer model (from HuggingFace) to use for local embeddings
# Examples: Xenova/all-MiniLM-L6-v2, Xenova/bge-small-en-v1.5
LOCAL_EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2

# --- Optional: Transformers Cache ---
# Specify a directory for @xenova/transformers.js (Node.js server) to cache models
# TRANSFORMERS_CACHE=./models